{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a740b602-ea8b-4e39-aa2b-7c63b4403682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb12b6-c589-4360-ace9-0bdfaced4ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: import transformers; \n",
    "except: \n",
    "  !pip install transformers\n",
    "  import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5379cd5-31d1-400a-b289-4ac62c732684",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_MLP(nn.Module):\n",
    "    def __init__(self,num_labels, MODEL_NAME='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pretrained_model_config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "        self.hidden_dropout_prob = self.pretrained_model_config.hidden_dropout_prob\n",
    "        self.hidden_size = self.pretrained_model_config.hidden_size \n",
    "        \n",
    "        self.model = AutoModel.from_pretrained(MODEL_NAME, self.pretrained_model_config)\n",
    "        # self.bert = BertModel.from_pretrained(pre_trained)\n",
    "        # self.hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # define new parameters for classifier\n",
    "        self.final_hidden = nn.Linear(self.hidden_size,self.hidden_size)\n",
    "        self.clf = nn.Linear(self.hidden_size, num_labels)\n",
    "        \n",
    "        # define variables for loss functions\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def cross_entropy(self, logits, labels):\n",
    "        cl_loss = self.loss(logits, labels)\n",
    "        \n",
    "        return cl_loss\n",
    "        \n",
    "    def forward(self,input_ids, attention_mask, labels, token_type_ids):\n",
    "        encoded_layers, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        encoded_layers = encoded_layers.permute(1, 0, 2)\n",
    "        \n",
    "        # enc_hiddens, (last_hidden, last_cell) = self.LSTM(pack_padded_sequence(encoded_layers, inputs[2])) \n",
    "        # output_hidden = torch.cat((last_hidden[0], last_hidden[1]), dim=1)\n",
    "        output_hidden = self.final_hidden(output_hidden)\n",
    "        output_hidden = torch.tanh(output_hidden)\n",
    "        output_hidden = F.dropout(output_hidden,self.hidden_dropout_prob)\n",
    "        \n",
    "        output = self.clf(output_hidden)\n",
    "        \n",
    "        loss = self.cross_entropy(output, labels)\n",
    "        \n",
    "        return (output, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b3566-17f9-4ac2-91ce-819c3de1c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mlp = BERT_MLP(MODEL_NAME='bert-base-uncased', num_labels = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66d2a8fd-825f-467d-9d8b-c1a67ae11161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b47e86-c01c-47f2-8133-b054fa8e8ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
